{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library\n",
    "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
    "## We create dataloader with dataset from torchvision, \n",
    "## and we dont have to download it seperately, all automatically done\n",
    "\n",
    "# Define batch size, batch size is how much data you feed for training in one iteration\n",
    "batch_size_train = 64 # We use a small batch size here for training\n",
    "batch_size_test = 1024 #\n",
    "\n",
    "# define how image transformed\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "#image datasets\n",
    "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=image_transform)\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                          train=False, \n",
    "                                          download=True,\n",
    "                                          transform=image_transform)\n",
    "#data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import matplotlib.pyplot as plt\n",
    "# We can check the dataloader\n",
    "_, (example_datas, labels) = next(enumerate(test_loader))\n",
    "sample = example_datas[0][0]\n",
    "# show the data\n",
    "plt.imshow(sample, cmap='gray', interpolation='none')\n",
    "print(\"Label: \"+ str(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "## We first import the pytorch nn module and optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## Then define the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 10\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        #dropout layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model and optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "device = \"cpu\"\n",
    "model = CNN().to(device) #using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "##define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "##define test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_415/1895196525.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm(train_loader, total=int(len(train_loader)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2fbd3703124b1ebc8a3ff78c2b0e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_415/4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3259, Accuracy: 9032/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1ebc0a977e4a019a64e57f47cf0f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2254, Accuracy: 9319/10000 (93%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cd13795d1b407eae9e0649d402af6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1901, Accuracy: 9447/10000 (94%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf6beaa999d4e63b1766be7e3ebb276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1628, Accuracy: 9520/10000 (95%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be09a229aff478aa15cc6e2abd81e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1503, Accuracy: 9549/10000 (95%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20735f968d0c44fdbe3730e30cc87443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1299, Accuracy: 9613/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e99fc6f1534d23afb3e53fa9453909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1282, Accuracy: 9635/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 7\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape torch.Size([1024, 1, 28, 28])\n",
      "output shape torch.Size([1024, 10])\n",
      "tensor([8, 1, 5,  ..., 1, 3, 8])\n",
      "tensor(8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_415/4020281764.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "# from PIL import Image\n",
    "\n",
    "# to_pil = transforms.ToPILImage()\n",
    "inf_data = example_datas\n",
    "print(f\"input shape {inf_data.shape}\")\n",
    "\n",
    "model.eval()\n",
    "inf_output = model(inf_data)\n",
    "\n",
    "print(f\"output shape {inf_output.shape}\")\n",
    "\n",
    "print(inf_output.argmax(dim=1))\n",
    "print(inf_output.argmax(dim=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mnist_torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_pbtxt='''\n",
    "name: \"mnist\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 1\n",
    "input [\n",
    "  {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [-1,1,28,28]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [-1,10]\n",
    "  }\n",
    "]\n",
    "\n",
    "instance_group [\n",
    "    {\n",
    "        count: 1\n",
    "        kind: KIND_CPU\n",
    "    }\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy torch save model\n",
    "import os\n",
    "p = f\"./models/{model_name}/{model_version}\"\n",
    "os.makedirs(p, exist_ok=True)\n",
    "torch.save(model, os.path.join(p, \"dummy_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./models/{model_name}/config.pbtxt\", \"w\") as f:\n",
    "    f.write(mnist_pbtxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# idempotent register (register + upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify to upload the whole folder\n",
    "from minio import Minio\n",
    "from model_registry import ModelRegistry\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_client = Minio(\"minio-service.kubeflow.svc.cluster.local:9000\",\n",
    "    access_key=\"minio\",\n",
    "    secret_key=\"minio123\",\n",
    "    secure=False  # only when you use http\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = ModelRegistry(\n",
    "    server_address=\"http://model-registry-service.kubeflow-user-example-com.svc.cluster.local\",\n",
    "    port=8080,\n",
    "    author=\"joel\",\n",
    "    is_secure=False  # Set to True if your Model Registry uses HTTPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(client, source, destination, bucket_name='models') -> (str, str):\n",
    "    # return (bucket, object string) if successful\n",
    "    # upload file into bucket\n",
    "    source_file = source\n",
    "    destination_file = destination\n",
    "\n",
    "    found = client.bucket_exists(bucket_name)\n",
    "    if not found:\n",
    "        client.make_bucket(bucket_name)\n",
    "        print('Created bucket', bucket_name)\n",
    "    else:\n",
    "        print('Bucket', bucket_name, 'already exists')\n",
    "\n",
    "    client.fput_object(bucket_name, destination_file, source_file)\n",
    "    print(source_file, 'successfully uploaded as object', destination_file, 'to bucket', bucket_name)\n",
    "    return bucket_name, destination\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register(registry, name, path, version, **kwargs) -> Any:\n",
    "    registry.register_model(name, path, model_format_name=kwargs.get('model_format_name', 'pytorch'), model_format_version=kwargs.get('model_format_version', '1'), version=version, description=kwargs.get('description', None), metadata=kwargs.get('metadata'))\n",
    "    return registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_reg(client, source, destination, registry, name, version, **kwargs) -> Any:\n",
    "    # if success return registry\n",
    "\n",
    "    bucket_name='models'\n",
    "    try:\n",
    "        upload(client, source, destination, bucket_name=bucket_name)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            client.remove_object(bucket_name, destination)\n",
    "        except:\n",
    "            print('Unexpected error in upload and remove')\n",
    "        finally:\n",
    "            print('Unexpected error in upload')\n",
    "            return\n",
    "\n",
    "    try:\n",
    "        return register(registry, name, f'{bucket_name}/{destination}', version, **kwargs)\n",
    "    except:\n",
    "        try:\n",
    "            client.remove_object(bucket_name, destination)\n",
    "        except:\n",
    "            print('Unexpected error in register and remove')\n",
    "        finally:\n",
    "            print('Unexpected error in register')\n",
    "            return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload(minio_client, './models/dummy_model.pt', 'pytorch/dummy_model.pt', bucket_name='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket models already exists\n",
      "./models/dummy_model.pt successfully uploaded as object pytorch/dummy_model.pt to bucket models\n"
     ]
    }
   ],
   "source": [
    "reg = upload_reg(minio_client, './models/dummy_model.pt', 'pytorch/dummy_model.pt', registry, 'mnist', 'v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Model: name='mnist' id='1' description=None external_id=None create_time_since_epoch='1761864364342' last_update_time_since_epoch='1761864364342' custom_properties=None owner='joel' state=<RegisteredModelState.LIVE: 'LIVE'> with ID 1\n"
     ]
    }
   ],
   "source": [
    "# model = reg.get_registered_model(\"mnist\")\n",
    "# print(\"Registered Model:\", model, \"with ID\", model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
